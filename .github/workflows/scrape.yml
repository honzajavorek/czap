name: scrape

on:
  push:
    branches:
      - main
  schedule:
    - cron: "0 4 * * *"  # every day at 4am
  workflow_dispatch:  # allows manual triggering of the workflow

# Allow GITHUB_TOKEN to deploy to GitHub Pages
permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  scrape:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Poetry
        run: pipx install poetry

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version-file: pyproject.toml
          cache: poetry

      - name: Install Python dependencies
        run: poetry install

      # For some reason the 'overwrite' option for the Scrapy feed exporters
      # doesn't work reliably for me Â¯\_(ãƒ„)_/Â¯
      - name: Clear data file
        run: rm items.json

      - name: Scrape
        run: poetry run scrapy crawl czap

      - name: Check that data got exported
        run: "[ -s items.json ] || exit 1"

      - name: Save to Git
        uses: EndBug/add-and-commit@v9
        with:
          add: items.json
          author_name: "scraper"
          author_email: "scraper@honzajavorek.cz"
          message: "update items ðŸ“¥"

      - name: Move files
        run: |
          mkdir -p site
          mv items.* site/

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v4
        with:
          path: ./site

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
